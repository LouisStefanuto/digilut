{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DigiLut Data Challenge (2024)","text":"<p>This project is my submission to the DigiLut competition.</p> <p>The DigiLut challenge, a collaborative project between Trustii.io and Foch Hospital and supported by the Health Data Hub and Bpifrance, aims to develop a medical decision support algorithm to diagnose graft rejection episodes in lung transplant patients by detecting pathological regions (A lesions) on transbronchial biopsies.</p> <p></p> <p> Install the project on your machine</p> <p> Discover my AI approach to solve this data challenge</p>"},{"location":"#contributing","title":"\ud83d\udc4b Contributing","text":"<p>If you encounter any issues with the repo or have suggestions for improvements, feel free to open an issue or submit a pull request.</p>"},{"location":"about/","title":"About","text":""},{"location":"about/#tools-used-in-the-project","title":"Tools used in the project","text":"<ul> <li> <p>Data pre-processing and analysis</p> <ul> <li>PyFAST: a library for TIFF image</li> <li>Openslide: a standard lib to open and plot WSI images</li> </ul> </li> <li> <p>Model Training</p> <ul> <li>Pytorch and Lightning for training</li> <li>MLflow for experiment monitoring and model registry</li> <li>Tensorboard for in-run loss and metrics monitoring</li> </ul> </li> <li> <p>Documentation</p> <ul> <li>Mkdocs: to generate static documentation websites from markdown files</li> <li>Mkdocs-Material: a theme for Mkdocs</li> </ul> </li> <li> <p>Miscellaneous</p> <ul> <li>Typer: for a fancy CLI</li> <li>Pydantic: for config validation</li> <li>Github Actions: for CI/CD</li> <li>Pytest: for testing some parts of the project</li> <li>Precommit: for quality checks before committing to the repo</li> </ul> </li> </ul>"},{"location":"approach/","title":"Patch classification","text":"<p>DigiLut is an object detection challenge. Yet the images are too big to apply YOLO/DETR models on them directly. Thus, I decided to rephrase the problem as a patch classification problem, followed by a post processing step, that converts predicted patches heat maps into bounding boxes.</p> <p>Steps:</p> <ol> <li>Convert the dataset of WSI slides into a labelled dataset of JPG patches</li> <li>Train a patch classification classifier</li> </ol> <pre><code>graph TD\n  A[Whole Slide Images dataset] --&gt;|PyFAST patchifies and keeps patches with tissue in it| C[Patches 256x256];\n  C --&gt; D[Assign binary labels to patches];\n  D --&gt; H[Train/Test split over patient IDs];\n  H --&gt; E[Train patches];\n  H --&gt; F[Test patches];\n  E --&gt; K[Undersample the train dataset to ensure a better label balance]\n  K --&gt; L[Cross validation split: GroupKFold over the patient IDs]\n  L --&gt; N[Train a ResNet model]\n  N --&gt;|Repeat over N folds| L;\n  N --&gt; O[Monitor training with Tensorboard]\n  N ---&gt; Q[N models trained = 1 ensemble of models];\n  N --&gt; P[Log experiment configuration and metrics in MLflow]\n  F --------&gt; R[Predict on test samples with the ensemble of models];\n  Q --&gt; R;</code></pre>"},{"location":"approach/#dataset-creation","title":"Dataset creation","text":"<ul> <li>Whole Slide Images (WSI .tiff images) are too big, we tile them into \\(256 \\times 256\\) patches, at \\(\\times 20\\) magnification level.</li> <li>FAST, a medical image processing library, is used to tile the images into patches. FAST has tissue segmentation tools, so we only save patches that contain cells. This saves a lot of memory and I/O operations because most of the WSI is white background.</li> <li>Then we assign binary (0/1) labels to each patch:<ul> <li>1 (positive) if IoU &gt; threshold, with one of the ground truth bounding boxes of the slide</li> <li>0 (negative) else.</li> </ul> </li> </ul> <p>Doing so we save around 10k patches per slide. The labels are highly imbalanced (1:1000 positive)</p>"},{"location":"approach/#training","title":"Training","text":"<ul> <li>We run cross validation (n=5) using a groupKFold strategy over the patient IDs to avoid train/test leakage.</li> <li>We then train a simple MLP classifier with a pretrained ResNet backbone using a BCE or focal loss<ul> <li>I considered other models pretrained on WSI images (like Phikon from Owkin), but they were too big for my machine. Maybe a LORA approach could have mitigated this issue.</li> </ul> </li> <li>By infering with this classifier on the whole slide, we get a scatter point of positive and negative patches at (x,y) coordinates.</li> </ul>"},{"location":"challenge/","title":"Challenge","text":"<p>The goal of the challenge is to detect lung rejection regions within whole slide images of lung tissue. This an object detection problem.</p> <p></p>"},{"location":"challenge/#dataset","title":"Dataset","text":"<p>For this challenge, the raw data are Whole Slide Images, in the <code>.tif</code> file format.</p>"},{"location":"challenge/#inputs","title":"Inputs","text":"<ul> <li>Train set: ~250 slides with annotated bounding boxes <pre><code>filename,x1,x2,y1,y2,max_x,max_y\nbGaslniO4a_a.tif,29348,30108,28404,29675,82944,197632\nbGaslniO4a_a.tif,11735,12379,70274,71195,82944,197632\n2qj5MlLLBT_a.tif,11185,12276,11571,12671,82944,196608\n2qj5MlLLBT_a.tif,14380,15583,11252,12434,82944,196608\n2qj5MlLLBT_a.tif,12162,13834,71136,72440,82944,196608\n2qj5MlLLBT_a.tif,59717,60925,69848,70838,82944,196608\n2qj5MlLLBT_b.tif,11740,12998,10358,11449,82944,196608\n2qj5MlLLBT_b.tif,61137,62039,12162,13157,82944,196608\n2qj5MlLLBT_b.tif,5089,6113,71851,72582,82944,196608\nKn5fOmiTn6_b.tif,15341,15908,170845,171896,82688,197632\n2XE4wBhzed_b.tif,15447,16761,142268,143025,82944,197888\n</code></pre></li> <li> <p>Test set: ~150 slides to predict <pre><code>filename,max_x,max_y,trustii_id\nhqi5y2OzZy_b.tif,82944,198144,1\n1xebGQuAM7_b.tif,82944,194048,2\n8xGdkL0vZt_a.tif,82944,197632,3\nLQj5lC48hB_a.tif,82688,196352,4\n9NlPhYAFUH_a.tif,82688,197888,5\n7YxmEi5lcF_a.tif,82688,197632,6\nQKwcTAZ3xm_a.tif,82688,197632,7\nM62FqXX2cW_a.tif,82688,198144,8\nBX9BSJROge_a.tif,111360,49920,9\n</code></pre></p> </li> <li> <p>Additionally, the organizers gave access to a +3000 images with no bounding boxes (not annotated). Yet we had slide-level labels (0/1), that tell if the slide contains some regions of interest.</p> </li> </ul> <pre><code>file_name;presence_of_lesion\nT1jPRk7jhJ.tif;1\ni9xm71KbYG.tif;0\nYMzaHPjyIm.tif;1\nOXRsXE5qy9.tif;1\n1Glok0uajd.tif;0\n3CUWGrWdHN.tif;0\nEFjhDwliZT.tif;0\nZgmwxif2Ro.tif;0\neUXQGwZBc0.tif;0\n4ANuJVsNqn.tif;0\n</code></pre>"},{"location":"challenge/#expected-submissions","title":"Expected submissions","text":"<p>We were asked to return our predicted bounding boxes for each slide. The number of expected bounding boxes per slide is given by the organizers.</p> <p>The submission file should look like this:</p> <pre><code>trustii_id,filename,y1,y2,x1,x2\n1,hqi5y2OzZy_b.tif,1,1,1,1\n2,1xebGQuAM7_b.tif,2,2,2,2\n3,8xGdkL0vZt_a.tif,3,3,3,3\n4,LQj5lC48hB_a.tif,4,4,4,4\n5,9NlPhYAFUH_a.tif,5,5,5,5\n6,7YxmEi5lcF_a.tif,6,6,6,6\n7,QKwcTAZ3xm_a.tif,7,7,7,7\n8,M62FqXX2cW_a.tif,8,8,8,8\n9,BX9BSJROge_a.tif,9,9,9,9\n10,M62FqXX2cW_a.tif,10,10,10,10\n11,7kiGhyiFBZ_a.tif,11,11,11,11\n12,0Rv3MjnLWH_b.tif,12,12,12,12\n13,Y56OlpOxAw_a.tif,13,13,13,13\n14,sMNRS3N2Bp_b.tif,14,14,14,14\n15,yJrCf0Bme3_a.tif,15,15,15,15\n16,w6vcLYRETL_b.tif,16,16,16,16\n</code></pre>"},{"location":"challenge/#evaluation-process","title":"Evaluation process","text":"<p>The challenge metric is the mean F2 score over the predicted bounding boxes, after thresholding at \\(GIoU &gt; 0.5\\).</p> <p>The organizers provide the number of expected boxes per slide. We have to submit exactly the same number of bounding boxes. Ofc their order doesn't matter.</p> <p>The challenge evaluation process goes as follows:</p> <ol> <li> <p>A predicted bounding box is classified as a true positive (TP) if its GIoU (Generalized Intersection Over Union) is above the 0.5 threshold for one of the ground truth bounding boxes of the slide.</p> <p> We get a batch of true positive, false positive and false negative samples (there is no false negative in object detection).</p> </li> <li> <p>Based on these TP, FP and FN, we compute the F2 score per slide (F2 score puts more emphasis on recall than F1 score)</p> </li> <li>Finally we take the mean F2 score over all the test slides.</li> </ol> <p>More details on the challenge page: DigiLut Data Challenge</p>"},{"location":"install/","title":"Install","text":"<p>This tutorial is for MacOS users. For Windows/Linux, take a look at this section.</p> <ol> <li> <p>Install Poetry and Python 3.12</p> <pre><code>brew install poetry\nbrew install python@3.12\n</code></pre> </li> <li> <p>Clone the repo</p> <pre><code>git clone ...\ncd digilut\n</code></pre> </li> <li> <p>The project makes use of PyFAST for slide processing. Follow this tutorial. For MacOS users, here is the command to run</p> <pre><code>brew install openslide libomp\n</code></pre> </li> <li> <p>Create a virtual environment</p> <pre><code>poetry install --with docs,dev\n</code></pre> </li> <li> <p>Test your installation</p> <pre><code>source $(poetry env info --path)/bin/activate \ndigilut --help\n</code></pre> <p>You should be prompted something like:</p> <pre><code>Usage: digilut [OPTIONS] COMMAND [ARGS]...                                                                                                        \n\nEntrypoint of Digilut's main CLI.                                                                                                                 \n\n\u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --install-completion          Install completion for the current shell.                                                                         \u2502\n\u2502 --show-completion             Show completion for the current shell, to copy it or customize the installation.                                  \u2502\n\u2502 --help                        Show this message and exit.                                                                                       \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 clean-bbox    Remove obvious labelling mistakes from the input bounding box csv and save a new cleaned dataset csv.                             \u2502\n\u2502 credits       Print credits with style.                                                                                                         \u2502\n\u2502 pyfast        Pyfast processing commands to patchify .tif WSI images.                                                                           \u2502\n\u2502 tiles         Commands for tiles.                                                                                                               \u2502\n\u2502 undersample   Undersample patches to solve class imbalance                                                                                      \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre> </li> </ol>"},{"location":"postprocessing/","title":"Post processing and submission generation","text":"<p>Warning</p> <p>The postprocessing is not implemented yet.</p> <p>I conducted some experiments but this part of the pipeline is still work in progress.</p> <p>With the patch classification pipeline, we get coarse segmentation maps of the slide.</p> <p>The DigiLut challenge required to predict bounding boxes. Thus, I want to add a postprocessing step to convert the masks into \\(N\\) bounding boxes (the \\(N\\) is given by the organizers for each slide).</p> <p>I want to give a try to 2 approaches:</p> <ol> <li>A clustering one, based on DBSCAN</li> <li>A union-fuse one</li> </ol>"},{"location":"postprocessing/#dbscan","title":"DBSCAN","text":"<ul> <li>To extract bounding boxes, we first assign them to clusters using DBSCAN.<ul> <li>DBSCAN has the advantage of classifing outliers in a \"-1\" cluster, this is useful to avoid huge bounding boxes at the next steps, as we take englobing bboxes</li> </ul> </li> <li>Finally we compute the englobing bounding boxes for each cluster.</li> <li>The submission file tells us how many N boxes are expected. So we only keep the N clusters with the most positive patches. If the number of predicted boxes is smaller than N, we pad with (0,0,0,0) predictions.</li> </ul> <p>Drawback: we need to find the optimal clusters parameters (minimal number of points, distance for points to be linked), that are image-dependent.</p>"},{"location":"postprocessing/#union-fuse","title":"Union-fuse","text":"<p>This technique is simpler and it requires no hyperparameter tuning.</p> <ul> <li>Fuse overlapping positive patches until no one overlaps.</li> <li>Remove all positive patches that don't have at least two positive neighbors (within their 8 neighbors). That removes most of the outliers/false positive/not dense clusters.</li> <li>Compute the englobing bounding boxes for each cluster.</li> <li>The submission file tells us how many N boxes are expected. So we only keep the N clusters with the most positive patches. If the number of predicted boxes is smaller than N, we pad with (0,0,0,0) predictions.</li> </ul>"},{"location":"references/","title":"References","text":"<p>To be completed ...</p>"},{"location":"results/","title":"Results","text":"<p>Here are the metrics and some heatmaps to visualize the results.</p>"},{"location":"results/#patch-classification","title":"Patch classification","text":""},{"location":"results/#metrics","title":"Metrics","text":"<p>Metrics were computed over the test set (20% of the annotated slides). The classification threshold is set at 0.5. The best model (without ensemble) yields the following results:</p> Metric Value Recall 0.5364 Precision 0.0336 F1 Score 0.0633"},{"location":"results/#examples","title":"Examples","text":"<p>I have added heatmaps to visualize the results directly on the slides. The slides are downsampled to reduce their size, resulting in lower resolution.</p> <p>The heatmaps confirm the metrics: the model typically detects positive patches but also triggers a significant number of false alarms.</p>"},{"location":"results/#successful-predictions","title":"Successful Predictions","text":"<p>Two zones match the ground truth bounding boxes. A third zone in the center represents a false positive (FP) cluster.</p> <p></p> <p>In some cases, the model demonstrates satisfactory discrimination capabilities.</p> <p></p> <p></p>"},{"location":"results/#failed-predictions","title":"Failed Predictions","text":"<p>Here, the model successfully detects a small bounding box. While large regions of the image do not trigger alarms, which is encouraging, some regions do incorrectly trigger the model.</p> <p></p> <p>Additionally, I noted that the model struggles with slides that have unusual staining patterns. I believe that implementing some stain normalization could be beneficial.</p> <p></p>"},{"location":"results/#detection","title":"Detection","text":"<p>To be continued ...</p>"},{"location":"trustii/","title":"Trustii","text":"<p>During the competition, the organizers gave access to a JupyterHub instance. Here are the steps to run the project on the platform. The commands are different because it was a Debian VM.</p> <p>To run on the Trustii platform, follow these steps:</p> <ol> <li> <p>Open a terminal</p> </li> <li> <p>Clone the repo</p> <pre><code>git clone ...\ncd digilut\n</code></pre> </li> <li> <p>Create a Conda env to force the python version</p> <pre><code>conda create -n env-digitut python=3.12\nconda init\nsource ~/.bashrc\nconda activate env_digilut\n</code></pre> </li> <li> <p>Install poetry</p> <pre><code>pip install poetry -q\n</code></pre> </li> <li> <p>Install FAST deps:</p> <p>Install deps (enter yes if asked):</p> <pre><code>sudo apt install libgl1 libopengl0 libopenslide0 libusb-1.0-0 libxcb-xinerama0\n</code></pre> <p>If errors encountered, run the following commands (enter yes if asked), then try again the previous command.</p> <pre><code>sudo apt update\nsudo apt --fix-broken install\nsudo apt install libpocl2\n</code></pre> <p>The last dependency of FAST is OpenCL. It depends on your CPU. Check your CPU specs:</p> <pre><code>cat /proc/cpuinfo\n</code></pre> <p>Then download the relevant driver. More doc here (for me it was Intel on Trustii).</p> <pre><code># Intel driver opencl. Other option is to go manual: https://github.com/intel/compute-runtime/releases (not sure if sudo apt-get install intel-gmmlib is needed, I ran it)\nsudo apt-get install intel-opencl-icd\n</code></pre> </li> <li> <p>Finally, install package deps</p> <pre><code>poetry install --with dev,docs\n</code></pre> </li> <li> <p>Test your installation:</p> <pre><code>source $(poetry env info --path)/bin/activate \ndigilut --help\n</code></pre> <p>You should be prompted something like:</p> <pre><code>Usage: digilut [OPTIONS] COMMAND [ARGS]...                                                                                                        \n\nEntrypoint of Digilut's main CLI.                                                                                                                 \n\n\u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --install-completion          Install completion for the current shell.                                                                         \u2502\n\u2502 --show-completion             Show completion for the current shell, to copy it or customize the installation.                                  \u2502\n\u2502 --help                        Show this message and exit.                                                                                       \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 clean-bbox    Remove obvious labelling mistakes from the input bounding box csv and save a new cleaned dataset csv.                             \u2502\n\u2502 credits       Print credits with style.                                                                                                         \u2502\n\u2502 pyfast        Pyfast processing commands to patchify .tif WSI images.                                                                           \u2502\n\u2502 tiles         Commands for tiles.                                                                                                               \u2502\n\u2502 undersample   Undersample patches to solve class imbalance                                                                                      \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre> </li> </ol>"},{"location":"cli/","title":"CLI","text":"<p>This package leverages Typer to create a Command Line Interface (CLI). Typer is a library that simplifies the creation of CLI applications by using Python 3.6+ type hints. It provides an intuitive and powerful way to define commands, arguments, and options. It is a more concise alternative to <code>argparse</code>.</p> <p>The CLI is the recommended way to interact with the main python scripts of the repo.</p> <ul> <li> <p> New to Typer?</p> <p>Never heard of Typer before? We've got you covered.</p> <p> Install the CLI</p> </li> <li> <p> CLI Commands</p> <p>Discover all the commands to run from your terminal.</p> <p> Read the CLI Documentation</p> </li> </ul>"},{"location":"cli/commands/","title":"<code>digilut</code>","text":"<p>Entrypoint of Digilut's main CLI.</p> <p>Usage:</p> <pre><code>$ digilut [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--install-completion</code>: Install completion for the current shell.</li> <li><code>--show-completion</code>: Show completion for the current shell, to copy it or customize the installation.</li> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>clean-bbox</code>: Remove obvious labelling mistakes from the...</li> <li><code>credits</code>: Print credits with style.</li> <li><code>pyfast</code>: Pyfast processing commands to patchify...</li> <li><code>tiles</code>: Commands for tiles.</li> <li><code>undersample</code>: Undersample patches to solve class imbalance</li> </ul>"},{"location":"cli/commands/#digilut-clean-bbox","title":"<code>digilut clean-bbox</code>","text":"<p>Remove obvious labelling mistakes from the input bounding box csv and save a new cleaned dataset csv.</p> <p>Usage:</p> <pre><code>$ digilut clean-bbox [OPTIONS] CSV_BBOXES CSV_OUTPUT\n</code></pre> <p>Arguments:</p> <ul> <li><code>CSV_BBOXES</code>: Bounding box csv to clean   [required]</li> <li><code>CSV_OUTPUT</code>: Name of the cleaned csv  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--show-plots / --no-show-plots</code>: Plot figures  [default: no-show-plots]</li> <li><code>--train / --no-train</code>: In train mode run some check on rows, disabled for validation.  [default: train]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/commands/#digilut-credits","title":"<code>digilut credits</code>","text":"<p>Print credits with style.</p> <p>Usage:</p> <pre><code>$ digilut credits [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/commands/#digilut-pyfast","title":"<code>digilut pyfast</code>","text":"<p>Pyfast processing commands to patchify .tif WSI images.</p> <p>Usage:</p> <pre><code>$ digilut pyfast [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>labels</code>: Create labels for the tiles.</li> <li><code>patchify-dataset</code>: Extracts tiles from a dataset of slides.</li> <li><code>patchify-slide</code>: Exports the TIFF file into PNG tiles of...</li> </ul>"},{"location":"cli/commands/#digilut-pyfast-labels","title":"<code>digilut pyfast labels</code>","text":"<p>Create labels for the tiles.</p> <p>A tile is positive if it intersects at more that XX% with a bounding box.</p> <p>Usage:</p> <pre><code>$ digilut pyfast labels [OPTIONS] CSV_BBOXES FOLDER_PATCHES CSV_LABELS\n</code></pre> <p>Arguments:</p> <ul> <li><code>CSV_BBOXES</code>: [required]</li> <li><code>FOLDER_PATCHES</code>: [required]</li> <li><code>CSV_LABELS</code>: [required]</li> </ul> <p>Options:</p> <ul> <li><code>--threshold-iou FLOAT</code>: [default: 0.1]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/commands/#digilut-pyfast-patchify-dataset","title":"<code>digilut pyfast patchify-dataset</code>","text":"<p>Extracts tiles from a dataset of slides. Calls patchify-slide over each slide in the folder.</p> <p>Usage:</p> <pre><code>$ digilut pyfast patchify-dataset [OPTIONS] [CSV_PATH] [IMAGES_DIR] [OUTPUT_DIR]\n</code></pre> <p>Arguments:</p> <ul> <li><code>[CSV_PATH]</code>: Path to the CSV file  [default: data/train.csv]</li> <li><code>[IMAGES_DIR]</code>: Folder containing the .tif slide images  [default: data/images]</li> <li><code>[OUTPUT_DIR]</code>: Output dir. Each slide will have a {outputdir}/{slide}  [default: outputs]</li> </ul> <p>Options:</p> <ul> <li><code>--save-engine TEXT</code>: Engine to save image. 'cv2' (recommended) OR 'pillow'  [default: cv2]</li> <li><code>--patch-size INTEGER</code>: Patch size (width and hieght)  [default: 256]</li> <li><code>--level INTEGER</code>: Zoom level. 0 is the best resolution  [default: 0]</li> <li><code>--overlap-percent FLOAT</code>: Percentage of overlap between patches  [default: 0.0]</li> <li><code>-f, --img_format TEXT</code>: Image format. PNG is better (no artifact) but it x5 heavier. Values: 'jpg', 'png'  [default: jpg]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/commands/#digilut-pyfast-patchify-slide","title":"<code>digilut pyfast patchify-slide</code>","text":"<p>Exports the TIFF file into PNG tiles of tissue.</p> <p>Usage:</p> <pre><code>$ digilut pyfast patchify-slide [OPTIONS] TIFF_PATH OUTPUT_DIR\n</code></pre> <p>Arguments:</p> <ul> <li><code>TIFF_PATH</code>: Path to the slide  [required]</li> <li><code>OUTPUT_DIR</code>: Output folder where patches will be saved  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--save-engine TEXT</code>: Engine to save image. 'cv2' (recommended) OR 'pillow'  [default: cv2]</li> <li><code>--patch-size INTEGER</code>: Patch size (width and hieght)  [default: 256]</li> <li><code>--level INTEGER</code>: Zoom level. 0 is the best resolution  [default: 0]</li> <li><code>--overlap-percent FLOAT</code>: Percentage of overlap between patches  [default: 0.0]</li> <li><code>--img-format TEXT</code>: Image format. PNG is better (no artifact) but it x5 heavier. Values: 'jpg', 'png'  [default: jpg]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/commands/#digilut-tiles","title":"<code>digilut tiles</code>","text":"<p>Commands for tiles.</p> <p>Usage:</p> <pre><code>$ digilut tiles [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>extract-from-dataset</code>: Extract tiles a dataset of tiles.</li> <li><code>extract-from-image</code>: Extract tiles from the slide.</li> <li><code>generate-labels</code>: (Deprecated) Create the labels for the tiles.</li> </ul>"},{"location":"cli/commands/#digilut-tiles-extract-from-dataset","title":"<code>digilut tiles extract-from-dataset</code>","text":"<p>Extract tiles a dataset of tiles. Calls extract_from_image over a folder of slides.</p> <p>Usage:</p> <pre><code>$ digilut tiles extract-from-dataset [OPTIONS] [CSV_PATH] [OUTPUT_DIR]\n</code></pre> <p>Arguments:</p> <ul> <li><code>[CSV_PATH]</code>: Path to the CSV file  [default: data/train.csv]</li> <li><code>[OUTPUT_DIR]</code>: Outputdir  [default: outputs]</li> </ul> <p>Options:</p> <ul> <li><code>--tile-size INTEGER</code>: Size of the tiles (height and width)  [default: 1024]</li> <li><code>--parallel / --no-parallel</code>: Enable multiprocessing.  [default: parallel]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/commands/#digilut-tiles-extract-from-image","title":"<code>digilut tiles extract-from-image</code>","text":"<p>Extract tiles from the slide.</p> <p>Usage:</p> <pre><code>$ digilut tiles extract-from-image [OPTIONS] PATH_TIFF OUTPUT_DIR\n</code></pre> <p>Arguments:</p> <ul> <li><code>PATH_TIFF</code>: Path to the TIFF file  [required]</li> <li><code>OUTPUT_DIR</code>: Output folder. The output will we saved in {outputdir}/{path_tiff.stem}  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--tile-size INTEGER</code>: Size of the tiles (height and width)  [default: 1024]</li> <li><code>-p, --no-parallel</code>: Disable multiprocessing.  [default: True]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/commands/#digilut-tiles-generate-labels","title":"<code>digilut tiles generate-labels</code>","text":"<p>Create the labels for the tiles. V1 Deprecated. Use digilut pyfast</p> <p>Usage:</p> <pre><code>$ digilut tiles generate-labels [OPTIONS] CSV_BBOXES SLIDE_FOLDER\n</code></pre> <p>Arguments:</p> <ul> <li><code>CSV_BBOXES</code>: Bounding box file.  [required]</li> <li><code>SLIDE_FOLDER</code>: Slide folder, that contains an <code>info</code> and a <code>tiles</code> subfolder.  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--iou-thres FLOAT</code>: Threshold Intersection over Union. If tile IOU &gt; with a bounding box, the tile is labbeled positive.  [default: 0.2]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/commands/#digilut-undersample","title":"<code>digilut undersample</code>","text":"<p>Undersample patches to solve class imbalance</p> <p>Usage:</p> <pre><code>$ digilut undersample [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>run</code>: Takes as input the set of possible patches...</li> </ul>"},{"location":"cli/commands/#digilut-undersample-run","title":"<code>digilut undersample run</code>","text":"<p>Takes as input the set of possible patches and returns a subset of them that will be used for building the training dataset.</p> <p>For each slide folder, checks the patches metadata.csv Keep N positive and N negative patches.</p> <p>Usage:</p> <pre><code>$ digilut undersample run [OPTIONS] CSV_PATCHES OUTPUT_BALANCED_PATCHES\n</code></pre> <p>Arguments:</p> <ul> <li><code>CSV_PATCHES</code>: [required]</li> <li><code>OUTPUT_BALANCED_PATCHES</code>: [required]</li> </ul> <p>Options:</p> <ul> <li><code>--sampling-strategy FLOAT</code></li> <li><code>--random-seed INTEGER</code>: [default: 1234]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/new_to_typer/","title":"New to Typer?","text":"<p>This package leverages Typer to create a Command Line Interface (CLI). Typer is a library that simplifies the creation of CLI applications by using Python 3.6+ type hints. It provides an intuitive and powerful way to define commands, arguments, and options. It is a more concise alternative to <code>argparse</code>.</p> <p>The CLI is the recommended way to interact with the main python scripts of the repo.</p>"},{"location":"cli/new_to_typer/#installation","title":"Installation","text":"<p>The CLI is automatically installed when you install the project with <code>poetry</code>:</p> <pre><code>poetry install\n</code></pre>"},{"location":"cli/new_to_typer/#use-the-cli","title":"Use the CLI","text":"<p>Using the CLI is straightforward. You can either use the alias <code>digilut</code> (recommended and fancy) or you can directly call the main python script:</p> <pre><code>digilut --help\n# OR\npython digilut/main.py --help\n</code></pre> <p>A help panel appears and walks you through the commands of the CLI.</p> <p>Each command is a wrapper around a function in a Python script.</p>"},{"location":"cli/new_to_typer/#cli-configuration","title":"CLI Configuration","text":"<p>The CLI's configuration (alias) is defined in the <code>pyproject.toml</code> file, under the <code>[tool.poetry.scripts]</code> section:</p> <pre><code>[tool.poetry.scripts]\ndigilut = \"digilut.main:app\"\n</code></pre> <p>That creates a <code>digilut</code> CLI, that links to the Typer <code>app</code> in <code>digilut.main.py</code>.</p>"},{"location":"cli/new_to_typer/#typer-autodoc","title":"Typer autodoc","text":"<p>Typer comes with auto documentation tools. Typer can parse the commands docstrings and type hints and convert them into Markdown. I wrapped the command line into a shell script for convenience.</p> <pre><code>scripts/autodoc_typer.sh\n</code></pre> <p>This will generate the <code>doc/cli/commands.md</code> file.</p> <p>Run this command everytime you update/create/remove a command.</p>"}]}