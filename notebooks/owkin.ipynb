{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: https://colab.research.google.com/drive/1yny79jQYAxN-ho5Fei2cXGuPEzl7kxUs#scrollTo=rvuec_zBJCy3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def prepare_dataset(\n",
    "    df: pd.DataFrame, root_dir: Path, patches_subfolder: str = \"patches\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Takes a openend dataframe as input and returns the dataframe expected by the\n",
    "    pytorch datasets\n",
    "    \"\"\"\n",
    "    expected_cols_present = set([\"slideName\", \"patchName\", \"label\"]) <= set(df.columns)\n",
    "    if not expected_cols_present:\n",
    "        raise ValueError(\"Missing mendatory columns in label CSV file.\")\n",
    "\n",
    "    df[\"imgPath\"] = (\n",
    "        root_dir.as_posix()\n",
    "        + \"/\"\n",
    "        + df.slideName\n",
    "        + \"/\"\n",
    "        + patches_subfolder\n",
    "        + \"/\"\n",
    "        + df.patchName\n",
    "        + \".jpg\"\n",
    "    )\n",
    "    return df[[\"imgPath\", \"label\"]]\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../patches_train/labels.csv\", index_col=0)\n",
    "df = prepare_dataset(df, Path(\"../patches_train/\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "# Custom dataset\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx, 0]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = int(self.dataframe.iloc[idx, 1])\n",
    "        return {\"image\": image, \"label\": label}\n",
    "\n",
    "\n",
    "dataset = CustomImageDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoImageProcessor, ViTModel\n",
    "\n",
    "# load an image\n",
    "image = Image.open(\"../patches_train/0SJ4TLT74S_b/patches/0_7_0_3584_1_256_256.jpg\")\n",
    "\n",
    "# load phikon\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"owkin/phikon\", use_fast=True)\n",
    "model = ViTModel.from_pretrained(\"owkin/phikon\", add_pooling_layer=False)\n",
    "\n",
    "# process the image\n",
    "inputs = image_processor(image, return_tensors=\"pt\")\n",
    "\n",
    "# get the features\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    features = outputs.last_hidden_state[:, 0, :]  # (1, 768) shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import (\n",
    "    ModelCheckpoint,\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    ")\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from transformers import AutoImageProcessor, ViTModel\n",
    "\n",
    "\n",
    "# Custom dataset\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx, 0]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = int(self.dataframe.iloc[idx, 1])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Focal Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, weight=None):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        bce_loss = self.bce_loss(logits, targets)\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "        return focal_loss\n",
    "\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.RandomRotation(45),\n",
    "            transforms.ColorJitter(\n",
    "                brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1\n",
    "            ),\n",
    "            transforms.GaussianBlur(kernel_size=(7, 7), sigma=(0.001, 0.1)),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    ),\n",
    "    \"val\": transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "class ImageClassificationModel(pl.LightningModule):\n",
    "    def __init__(self, class_weights):\n",
    "        super(ImageClassificationModel, self).__init__()\n",
    "        # Load the new encoder model from the timm library\n",
    "        self.encoder = timm.create_model(\n",
    "            model_name=\"hf-hub:1aurent/vit_base_patch16_224.owkin_pancancer\",\n",
    "            pretrained=True,\n",
    "        ).eval()\n",
    "\n",
    "        # Freeze the encoder model\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Get model specific transforms (normalization, resize)\n",
    "        self.data_config = timm.data.resolve_model_data_config(self.encoder)\n",
    "        self.transforms = timm.data.create_transform(\n",
    "            **self.data_config, is_training=False\n",
    "        )\n",
    "\n",
    "        # Get the number of features from the encoder\n",
    "        num_features = self.encoder.num_features\n",
    "\n",
    "        # Two-layer classifier with ReLU activation\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "        # Calculate the pos_weight\n",
    "        self.criterion = FocalLoss(weight=class_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # inputs = torch.stack([self.transforms(img) for img in x])\n",
    "        inputs = self.transforms(x)\n",
    "        outputs = self.encoder(inputs)\n",
    "        features = outputs\n",
    "        return self.classifier(features)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        labels = labels.float().view(-1, 1)\n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        preds = torch.sigmoid(outputs) > 0.5\n",
    "        preds = preds.int()\n",
    "        acc = torch.sum(preds == labels.data).float() / len(labels)\n",
    "        f1 = f1_score(labels.cpu(), preds.cpu())\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_f1\", f1, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        labels = labels.float().view(-1, 1)\n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        preds = torch.sigmoid(outputs) > 0.5\n",
    "        preds = preds.int()\n",
    "        acc = torch.sum(preds == labels.data).float() / len(labels)\n",
    "        f1 = f1_score(labels.cpu(), preds.cpu())\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_f1\", f1, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=LR)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode=\"min\", factor=0.5, patience=3, min_lr=1e-7\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\"scheduler\": scheduler, \"monitor\": \"val_loss\"},\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digilut-YZcGrZfE-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
