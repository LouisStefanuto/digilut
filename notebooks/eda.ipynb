{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../data\"\n",
    "\n",
    "LABEL_TRAIN = Path(DATA_FOLDER, \"train.csv\")\n",
    "LABEL_VAL = Path(DATA_FOLDER, \"validation.csv\")\n",
    "LABEL_SUB = Path(DATA_FOLDER, \"submission_sample.csv\")\n",
    "LABEL_PRESENCE = Path(DATA_FOLDER, \"presence_of_lesion.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Train label dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset. Expected: filename, 4 box coords, shape\n",
    "\n",
    "df_train = pd.read_csv(LABEL_TRAIN)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((df_train.x2 - df_train.x1).describe())\n",
    "print((df_train.y2 - df_train.y1).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.filename.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will run inference on this file. We expect to find filename, shape, and ID (1-indexed).\n",
    "\n",
    "df_val = pd.read_csv(LABEL_VAL)\n",
    "df_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The organizers provide a blank submission file.\n",
    "# It gives us insights about the expected prediction format (comma separated).\n",
    "\n",
    "df_submission = pd.read_csv(LABEL_SUB)\n",
    "df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are multiple rows per filename.\n",
    "# The organizers give us the number of expected boxes.\n",
    "\n",
    "df_submission.filename.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Check intersection between datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_files_train = set(df_train.filename)\n",
    "set_files_val = set(df_val.filename)\n",
    "set_files_sub = set(df_submission.filename)\n",
    "\n",
    "print(\"Count of unique files per dataset:\")\n",
    "print(f\"- Train: {len(df_train):,} rows, {len(set_files_train):,} unique filenames\")\n",
    "print(f\"- Val: {len(df_val):,} rows, {len(set_files_val):,} unique filenames\")\n",
    "print(f\"- Sub: {len(df_submission):,} rows, {len(set_files_sub):,} unique filenames\\n\")\n",
    "\n",
    "# Confirmation that the filenames of the submission file are indeed the ones of the val set\n",
    "print(\"Are val and submission sets identical? (Expected: True):\")\n",
    "print(set_files_val == set_files_sub, \"\\n\")\n",
    "\n",
    "# Check leakage between train and val\n",
    "print(\"Check leakage between train and val\")\n",
    "print(\"train VS val :\", len(set_files_train & set_files_val), \"commmon elements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "# Presence of legion\n",
    "\n",
    "The organizers provided an extra CSV file that tells us if a slide contains or not some boxes.\n",
    "\n",
    "Thus, we can separate labels into 2 categories:\n",
    "- the \"bounding boxes\" are strong labels, high quality, but only on 25% of the dataset\n",
    "- the \"presence of legion\" labels are weak labels, contain less information, but cover 100% of the dataset.\n",
    "\n",
    "From it, I see one way of leveraging the two categories:\n",
    "1. Pretrain a basemodel in a self supervized fashion, with contrastive losses, to return good tile embeddings\n",
    "2. Finetune this base model on the bounding box dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_presence = pd.read_csv(LABEL_PRESENCE, sep=\";\")\n",
    "df_presence.sort_values(\"file_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the positive slides are all in LABEL_TRAIN\n",
    "set_files_pos = set(df_presence[df_presence.presence_of_lesion == 1].file_name)\n",
    "set_files_neg = set(df_presence[df_presence.presence_of_lesion == 0].file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the presence of lesion file, the name have no suffixes\n",
    "\n",
    "files = []\n",
    "for file in set_files_train:\n",
    "    name = file.split(\"_\")[0] + \".tif\"\n",
    "    if name not in set_files_pos:\n",
    "        files.append(file)\n",
    "\n",
    "\n",
    "print(\"Number of files in train.csv, with bboxes (so they are positive)\")\n",
    "print(\"but they are labelled as negative in the presence of lesion file:\", len(files))\n",
    "print(\"If we use these weak labels, we should fix them first.\")\n",
    "\n",
    "# See https://app.trustii.io/datasets/1526/forums/148/messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
