{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from digilut.dataset import NpyDataset\n",
    "\n",
    "csv_labels = \"../patches/labels_balanced_test.csv\"\n",
    "folder_embeddings = \"../embeddings/\"\n",
    "\n",
    "npy_dataset = NpyDataset(csv_labels, folder_embeddings)\n",
    "\n",
    "# Check the shapes of X and y\n",
    "print(f\"Shape of X: {npy_dataset.X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Replace with the path to your saved model file\n",
    "models_folder = \"models/\"\n",
    "model_names = os.listdir(models_folder)\n",
    "\n",
    "# Load the saved models\n",
    "models = []\n",
    "for model_name in model_names:\n",
    "    model = joblib.load(models_folder + model_name)\n",
    "    models.append(model)\n",
    "    print(f\"Model loaded from {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X = npy_dataset.X\n",
    "\n",
    "y_preds = []\n",
    "for model in models:\n",
    "    y_pred = model.predict_proba(X)\n",
    "    y_preds.append(y_pred)\n",
    "\n",
    "y_pred = np.array(y_preds).mean(axis=0)[:, 1] > 0.5\n",
    "y_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert preds into dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_preds = pd.DataFrame(\n",
    "    {\n",
    "        \"patientID\": npy_dataset.patient_ids,\n",
    "        \"slideID\": npy_dataset.slide_ids,\n",
    "        \"slidePath\": npy_dataset.names,\n",
    "        \"preds\": y_pred.astype(int),\n",
    "    }\n",
    ")\n",
    "df_preds = df_preds[df_preds.preds == 1]\n",
    "df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds.to_csv(\"../patches/predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have predictions for each tile.\n",
    "\n",
    "Let's create bounding boxes from 2D predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.read_csv(\"../patches/predictions.csv\", index_col=0)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split slide paths into columns to isolate coords\n",
    "\n",
    "coords = []\n",
    "for i, row in preds.iterrows():\n",
    "    path = row.slidePath\n",
    "    path = path.split(\".jpg\")[0]\n",
    "    pathName, coord = path.split(\"/patches/\")\n",
    "    pathName = pathName.split(\"patches/\")[1]\n",
    "    coord = coord.split(\"_\")\n",
    "    coords.append((pathName, *coord))\n",
    "\n",
    "coords\n",
    "\n",
    "df_coords = pd.DataFrame(\n",
    "    coords,\n",
    "    columns=[\n",
    "        \"pathName\",\n",
    "        \"patch_id_x\",\n",
    "        \"patch_id_y\",\n",
    "        \"x_pos\",\n",
    "        \"y_pos\",\n",
    "        \"patch_level\",\n",
    "        \"patch_width\",\n",
    "        \"patch_height\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "df_full = pd.concat([preds, df_coords], axis=1)\n",
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to this table the max coordinates of the blob\n",
    "max_coords = pd.read_csv(\"../data/train_cleaned.csv\", index_col=0)[\n",
    "    [\"slideName\", \"max_x\", \"max_y\"]\n",
    "].drop_duplicates()\n",
    "df_final = df_full.merge(max_coords, left_on=\"pathName\", right_on=\"slideName\")\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final[[\"pathName\", \"x_pos\", \"y_pos\"]]\n",
    "df_final[\"x_pos\"] = pd.to_numeric(df_final[\"x_pos\"])\n",
    "df_final[\"y_pos\"] = pd.to_numeric(df_final[\"y_pos\"])\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with the nb of bboxes expected per slide\n",
    "df_test = pd.read_csv(\"../data/train.csv\")\n",
    "bboxes_per_slide_dict = df_test.filename.value_counts().to_dict()\n",
    "bboxes_per_slide_dict = {\n",
    "    k.split(\".tif\")[0]: v for k, v in bboxes_per_slide_dict.items()\n",
    "}\n",
    "bboxes_per_slide_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "from digilut.create_bbox import get_n_most_recurrent_from_dict, plot_clusters\n",
    "\n",
    "# Get slide names unique\n",
    "unique_path_names = set(df_final.pathName)\n",
    "final_predictions = []\n",
    "\n",
    "\n",
    "for path_name in unique_path_names:\n",
    "    bboxes_kept = []\n",
    "\n",
    "    # Extract the predictions for this slide\n",
    "    pixels = df_final[df_final.pathName == path_name].copy()\n",
    "    pixels.drop(columns=[\"pathName\"], inplace=True)\n",
    "    print(path_name)\n",
    "    print(pixels.values.shape)\n",
    "\n",
    "    # Perform DBSCAN clustering\n",
    "    X = pixels.values\n",
    "    db = DBSCAN(eps=5000, min_samples=3).fit(X)\n",
    "    labels = db.labels_\n",
    "    pixels[\"cluster_id\"] = labels\n",
    "\n",
    "    # Plots\n",
    "    # plot_clusters(X, labels, path_name)\n",
    "\n",
    "    # Count nb positives patches per cluster (except the -1 one, outliers)\n",
    "    occurences = pd.Series(labels).value_counts().to_dict()\n",
    "    print(\"Occurences per cluster:\", occurences)\n",
    "    occurences.pop(-1)\n",
    "\n",
    "    # Keep the n biggest clusters, k is the nb of expected clusters\n",
    "    k = bboxes_per_slide_dict[path_name]\n",
    "    clusters_to_keep = get_n_most_recurrent_from_dict(occurences, k)\n",
    "    print(\"most occurent:\", clusters_to_keep)\n",
    "    pixels_kept_for_slide = pixels[pixels[\"cluster_id\"].isin(clusters_to_keep)]\n",
    "\n",
    "    # Get bounding box for each cluster\n",
    "    for cluster_id in clusters_to_keep:\n",
    "        cluster_pixels = pixels[pixels[\"cluster_id\"] == cluster_id]\n",
    "        final_predictions.append(\n",
    "            {\n",
    "                \"filename\": path_name,\n",
    "                \"x1\": cluster_pixels[\"x_pos\"].min(),\n",
    "                \"x2\": cluster_pixels[\"x_pos\"].max() + 256,\n",
    "                \"y1\": cluster_pixels[\"y_pos\"].min(),\n",
    "                \"y2\": cluster_pixels[\"y_pos\"].max() + 256,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    # If not enough bounding boxes predicted, patch with null boxes\n",
    "    for i in range(len(clusters_to_keep) - k):\n",
    "        final_predictions.append(\n",
    "            {\"filename\": path_name, \"x1\": 0, \"x2\": 0, \"y1\": 0, \"y2\": 0},\n",
    "        )\n",
    "\n",
    "df_final_predictions = pd.DataFrame(final_predictions).sort_values(\"filename\")\n",
    "df_final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_predictions.to_csv(\"bboxes_predicted.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format bboxes file for submission\n",
    "\n",
    "Goal: Last step, match predicted bboxes with trustii_id\n",
    "\n",
    "The idea is to sort the 2 dataframes per filename.\n",
    "\n",
    "Assumption:\n",
    "- We expect them to be have the same number of bboxes for each filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "submission_template = pd.read_csv(\"../data/submission_sample.csv\")\n",
    "submission_template.sort_values(\"filename\", inplace=True)\n",
    "submission_template.drop(columns=[\"x1\", \"x2\", \"y1\", \"y2\"], inplace=True)\n",
    "\n",
    "bboxes_predicted = pd.read_csv(\"bboxes_predicted.csv\", index_col=0)\n",
    "bboxes_predicted\n",
    "\n",
    "print(submission_template.shape)\n",
    "print(bboxes_predicted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Expected (true):\", len(submission_template) == len(bboxes_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission = pd.concat([submission_template, bboxes_predicted], axis=1)\n",
    "final_submission.sort_values(\"trustii_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission.to_csv(\"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digilut-YZcGrZfE-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
