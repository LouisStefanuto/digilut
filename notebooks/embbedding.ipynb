{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained model for feature extraction\n",
    "\n",
    "Goal: we first test a pretrained embedding model from Owkin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "# get example histology image\n",
    "img = Image.open(\n",
    "    urlopen(\"https://github.com/owkin/HistoSSLscaling/raw/main/assets/example.tif\")\n",
    ")\n",
    "\n",
    "# load model from the hub\n",
    "model = timm.create_model(\n",
    "    model_name=\"hf-hub:1aurent/vit_base_patch16_224.owkin_pancancer\",\n",
    "    pretrained=True,\n",
    ").eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "# input is a (batch_size, num_channels, img_size, img_size) shaped tensor\n",
    "data = transforms(img).unsqueeze(0)\n",
    "# output is a (batch_size, num_features) shaped tensor\n",
    "output = model(data)\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an embedding pipeline\n",
    "\n",
    "Convert JPG/PNG patches into .npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import numpy as np\n",
    "import timm\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def main(image_folder: Path, output_folder: Path) -> None:\n",
    "    # Ensure output_folder exists\n",
    "    output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Load model from the hub\n",
    "    model = timm.create_model(\n",
    "        model_name=\"hf-hub:1aurent/vit_base_patch16_224.owkin_pancancer\",\n",
    "        pretrained=True,\n",
    "    )\n",
    "    model.eval()\n",
    "    model.to(\"mps\")\n",
    "\n",
    "    # Get model specific transforms (normalization, resize)\n",
    "    data_config = timm.data.resolve_model_data_config(model)\n",
    "    transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "    # Process each image in the folder\n",
    "    imgs = [image_folder / f for f in os.listdir(image_folder) if f.endswith(\".jpg\")]\n",
    "    for image_path in tqdm(imgs, total=len(imgs)):\n",
    "        try:\n",
    "            # Load image\n",
    "            img = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "            # Apply transformations\n",
    "            data = transforms(img).unsqueeze(0).to(\"mps\")\n",
    "\n",
    "            # Generate embeddings\n",
    "            with torch.no_grad():\n",
    "                output = model(data)\n",
    "\n",
    "            # Store embeddings\n",
    "            embedding = output.squeeze(0).cpu().numpy()\n",
    "            output_file = output_folder / (image_path.stem + \".npy\")\n",
    "            np.save(output_file, embedding)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path.name}: {e}\")\n",
    "\n",
    "    # Save embeddings to file\n",
    "    print(f\"Embeddings saved to {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's embed all the patches of a slide\n",
    "\n",
    "Speed on a M2: 5569 patches in [02:29<00:00, 37.16 patches/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your image folder and output file here\n",
    "patches_folder = \"../processed/2qj5MlLLBT_a/patches\"\n",
    "\n",
    "# patches_folder = \"../image_to_embed/\"\n",
    "output_folder = \"../embeddings/\"\n",
    "\n",
    "main(Path(patches_folder), Path(output_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then read the `npy` embeddings and convert them back into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open one npy file\n",
    "import numpy as np\n",
    "\n",
    "embedding_file = \"../embeddings/27_589_6912_150784_0_256_256.npy\"\n",
    "\n",
    "# Load the .npy file\n",
    "embeddings = np.load(embedding_file)\n",
    "\n",
    "# Print or inspect the loaded embeddings\n",
    "print(embeddings)\n",
    "print(f\"Shape of the embeddings: {embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding analyses\n",
    "\n",
    "Let's analyze how the patches are placed in the latent space. Use UMap for dimension reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_files = [Path(output_folder, f) for f in os.listdir(output_folder)]\n",
    "embeddings = [np.load(npy_file) for npy_file in npy_files]\n",
    "embeddings = np.array(embeddings)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "reducer = umap.UMAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = reducer.fit_transform(embeddings)\n",
    "reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(reduced[:, 0], reduced[:, 1])\n",
    "plt.show()\n",
    "\n",
    "# Clusters appear, it would be interesting to analyze them\n",
    "# One cluster must be glass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digilut-YZcGrZfE-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
