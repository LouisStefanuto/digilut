{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment\n",
    "\n",
    "Bottleneck: load all patch embeddings in one big matrix = heavy in RAM\n",
    "You may have to split your datasets manually in multiple parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from digilut.dataset import NpyDataset\n",
    "\n",
    "csv_labels = \"../patches/labels_balanced_train.csv\"\n",
    "folder_embeddings = \"../embeddings/\"\n",
    "\n",
    "npy_dataset = NpyDataset(csv_labels, folder_embeddings)\n",
    "\n",
    "# Check the shapes of X and y\n",
    "print(f\"Shape of X: {npy_dataset.X.shape}\")\n",
    "print(f\"Shape of y: {npy_dataset.y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    precision_recall_fscore_support,\n",
    "    fbeta_score,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedGroupKFold, KFold, GroupKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from digilut.dataset import count_occ_labels\n",
    "\n",
    "# Extract dataset info for splitting\n",
    "patch_indices = npy_dataset.df.index\n",
    "patch_slides = npy_dataset.df.slideName\n",
    "patch_labels = npy_dataset.df.label\n",
    "seed = 1234\n",
    "models_folder = \"models\"\n",
    "\n",
    "verbose = False\n",
    "n_repeats = 1\n",
    "n_folds = 5\n",
    "train_metrics, val_metrics = [], []\n",
    "test_logits = []\n",
    "\n",
    "cv_start_time = datetime.now()\n",
    "\n",
    "for repeat in range(n_repeats):\n",
    "    print(f\"Running cross-validation #{repeat+1}\")\n",
    "\n",
    "    # GroupKFold for creating folds, to avoid contamination\n",
    "    cv_skfold = GroupKFold(n_splits=n_folds)\n",
    "    cv_splits = cv_skfold.split(X=patch_indices, groups=patch_slides)\n",
    "\n",
    "    for i, (train_indices, val_indices) in enumerate(cv_splits):\n",
    "        fold_start_time = datetime.now()\n",
    "        print(f\"Running cross-validation on split #{i+1}\")\n",
    "\n",
    "        # Create datasets\n",
    "        X_train = npy_dataset.X[train_indices, :]\n",
    "        y_train = npy_dataset.y[train_indices]\n",
    "        X_val = npy_dataset.X[val_indices, :]\n",
    "        y_val = npy_dataset.y[val_indices]\n",
    "\n",
    "        print(\"Train: {}\".format(X_train.shape))\n",
    "        print(\"Val: {}\".format(X_val.shape))\n",
    "        print(\"Labels train: {}\".format(count_occ_labels(y_train)))\n",
    "        print(\"Labels val: {}\".format(count_occ_labels(y_val)))\n",
    "\n",
    "        model = MLPClassifier(\n",
    "            random_state=42,\n",
    "            verbose=verbose,\n",
    "            hidden_layer_sizes=(64),\n",
    "            learning_rate_init=1e-4,\n",
    "            learning_rate=\"adaptive\",\n",
    "            alpha=1e-3,\n",
    "            max_iter=100,\n",
    "            shuffle=True,\n",
    "            tol=1e-7,\n",
    "        )\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predictions on the validation set\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_val, y_val_pred)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_val, y_val_pred)\n",
    "        f2 = fbeta_score(y_val, y_val_pred, beta=2)\n",
    "        auc = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "        # Store metrics\n",
    "        val_metrics.append(\n",
    "            {\n",
    "                \"fold\": i,\n",
    "                \"repeat\": repeat,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"f1\": f1,\n",
    "                \"f2\": f2,\n",
    "                \"auc\": auc,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Print metrics\n",
    "        print(\"Validation Metrics:\")\n",
    "        print(\"- Accuracy: {:.4f}\".format(accuracy))\n",
    "        print(\"- Precision: {}\".format(precision))\n",
    "        print(\"- Recall: {}\".format(recall))\n",
    "        print(\"- F1 Score: {}\".format(f1))\n",
    "        print(\"- F2 Score: {}\".format(f2))\n",
    "        print(\"- ROC-AUC: {}\".format(auc))\n",
    "\n",
    "        # print(classification_report(y_val, y_val_pred))\n",
    "        print(\"Confusion matrix:\\n{}\".format(confusion_matrix(y_val, y_val_pred)))\n",
    "\n",
    "        # Save the model after training\n",
    "        model_filename = f\"{models_folder}/mlp_model_repeat{repeat+1}_fold{i+1}.pkl\"\n",
    "        joblib.dump(model, model_filename)\n",
    "        print(f\"Model saved to {model_filename}\")\n",
    "\n",
    "        # Append fold local metrics\n",
    "        fold_end_time = datetime.now()\n",
    "        fold_running_time = fold_end_time - fold_start_time\n",
    "        print(\"\\n--------- Finished in {} ---------\\n\".format(fold_running_time))\n",
    "\n",
    "\n",
    "cv_end_time = datetime.now()\n",
    "cv_total_time = cv_end_time - cv_start_time\n",
    "print(\"Total cross-validation time: {}\".format(cv_total_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digilut-YZcGrZfE-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
